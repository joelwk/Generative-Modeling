{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import layers, models, losses, callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "from utils.process import main\n",
    "data = pd.read_csv('../sampled_data.csv').sample(25000)\n",
    "train_ds, val_ds, test_ds, combined_vocab = main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. General Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_text.general_generative_keras.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative_text.general_generative_keras.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "from generative_text.general_generative_keras.evaluate import TextGenerator, CustomSchedule\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative_text/configkeras.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "LOAD_MODEL = False\n",
    "MODEL_PATH = './models/general_generative/model_1.h5'\n",
    "\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/general_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(index_to_word=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_text.general_generative_keras.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.general_generative_keras.evaluate import TextGenerator, CustomSchedule\n",
    "\n",
    "MODEL_PATH = './models/general_generative/model_1.h5'\n",
    "with custom_object_scope({'CustomSchedule': CustomSchedule, 'TransformerBlock': TransformerBlock, 'TokenAndPositionEmbedding': TokenAndPositionEmbedding}):\n",
    "    model = load_model(MODEL_PATH)\n",
    "\n",
    "test_text_gen = TextGenerator(model=model, index_to_word=combined_vocab, top_k=15, generation_type='general', sampling_type='top_k')\n",
    "info = test_text_gen.generate(\"Today in the news\", max_tokens=50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Custom Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from generative_text.general_chat_custom.preprocessing import DirectoryManager  \n",
    "from generative_text.general_chat_custom.preprocessing import initialize_and_prepare  \n",
    "from generative_text.general_chat_custom.processing import process_and_load_data\n",
    "import pandas as pd\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative_text/configcustom.ini')\n",
    "config_params = config['params']\n",
    "params = {key: config_params[key] for key in config_params}\n",
    "base_directory = params['dataset_path']\n",
    "max_len = int(params['max_len'])\n",
    "vocab_size = int(params['vocab_size'])\n",
    "embedding_dim = int(params['embedding_dim'])\n",
    "num_heads = int(params['n_heads'])\n",
    "num_layers = int(params['n_layers'])\n",
    "key_dim = int(params['key_dim'])\n",
    "ff_dim = int(params['feed_forward_dim'])\n",
    "dropout_rate = float(params['dropout'])\n",
    "warmup_steps = int(params['warmup_steps'])\n",
    "activation = params['activation']\n",
    "replies = pd.read_csv('../replies.csv')\n",
    "config_directories = DirectoryManager.generate_config(base_directory)\n",
    "DirectoryManager.create_directories(config_directories) \n",
    "meta_data_dir = config_directories['meta_data_dir']\n",
    "\n",
    "# Load supporting data\n",
    "text_pairs, voc_comment, voc_response_comment = initialize_and_prepare(base_directory, replies)\n",
    "# Load data\n",
    "train_ds, val_ds, test_ds, thread_vectorizer, comment_vectorizer  = process_and_load_data(replies)\n",
    "\n",
    "# Count and view tokens\n",
    "comment_tokens, response_comment_tokens = set(), set()\n",
    "comment_maxlen, response_maxlen = 0, 0\n",
    "for comment, response in text_pairs:\n",
    "    comment_tok, response_tok = comment.split(), response.split()\n",
    "    comment_maxlen = max(comment_maxlen, len(comment_tok))\n",
    "    response_maxlen = max(response_maxlen, len(response_tok))\n",
    "    comment_tokens.update(comment_tok)\n",
    "    response_comment_tokens.update(response_tok)\n",
    "    \n",
    "print(f\"Total Comment tokens: {len(comment_tokens)}\")\n",
    "print(f\"Total Response tokens: {len(response_comment_tokens)}\")\n",
    "print(f\"Max Comment length: {comment_maxlen}\")\n",
    "print(f\"Max Response length: {response_maxlen}\")\n",
    "print(f\"{len(text_pairs)} total pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_text.general_chat_custom.tnn import transformer, masked_loss, masked_accuracy\n",
    "from generative_text.general_chat_custom.tnn import CustomSchedule\n",
    "from generative_text.general_chat_custom.PositionalEmbedding import PositionalEmbedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Create model\n",
    "model = transformer(num_layers, num_heads, max_len, key_dim, ff_dim,\n",
    "                    len(comment_tokens), len(response_comment_tokens), dropout_rate)\n",
    "# Set custom earning rate\n",
    "lr = CustomSchedule(key_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "model.compile(loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy])\n",
    "# View model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy])\n",
    "\n",
    "# Set up callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_masked_accuracy', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(f'./models/model_1.keras')\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "epochs = 5\n",
    "history = model.fit(train_ds, epochs = epochs, validation_data = val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True, figsize=(10, 6))\n",
    "fig.suptitle('Training history')\n",
    "# Get the actual number of training epochs\n",
    "actual_epochs = len(history.history[\"loss\"])\n",
    "x = list(range(1, actual_epochs + 1))\n",
    "axs[0].plot(x, history.history[\"loss\"], alpha=0.5, label=\"loss\")\n",
    "axs[0].plot(x, history.history[\"val_loss\"], alpha=0.5, label=\"val_loss\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[1].plot(x, history.history[\"masked_accuracy\"], alpha=0.5, label=\"masked_accuracy\")\n",
    "axs[1].plot(x, history.history[\"val_masked_accuracy\"], alpha=0.5, label=\"val_masked_accuracy\")\n",
    "axs[1].set_ylabel(\"Masked Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "import random\n",
    "custom_objects = {\"PositionalEmbedding\": PositionalEmbedding,\n",
    "                  \"CustomSchedule\": CustomSchedule,\n",
    "                  \"masked_loss\": masked_loss,\n",
    "                  \"masked_accuracy\": masked_accuracy}\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    model = tf.keras.models.load_model(f'./models/model_1.keras')\n",
    "\n",
    "# Translate function\n",
    "# Translate function\n",
    "def translate(sentence):\n",
    "    \"\"\"Create the translated sentence\"\"\"\n",
    "    enc_tokens = thread_vectorizer([sentence])\n",
    "    enc_tokens = tf.reshape(enc_tokens, (1, -1))  # Reshape to include batch dimension\n",
    "    lookup = list(comment_vectorizer.get_vocabulary())\n",
    "    start_sentinel, end_sentinel = \"[start]\", \"[end]\"\n",
    "    output_sentence = [start_sentinel]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        vector = comment_vectorizer([\" \".join(output_sentence)])\n",
    "        dec_tokens = tf.reshape(vector[:, :-1], (1, -1))  # Reshape to include batch dimension\n",
    "        pred = model([enc_tokens, dec_tokens])\n",
    "        \n",
    "        word_index = tf.argmax(pred[0, i, :]).numpy()\n",
    "        word = lookup[word_index]\n",
    "        output_sentence.append(word)\n",
    "        \n",
    "        if word == end_sentinel:\n",
    "            break\n",
    "            \n",
    "    return output_sentence\n",
    "\n",
    "# Testing\n",
    "test_count = 5\n",
    "for n in range(test_count):\n",
    "    thread, comment = random.choice(text_pairs)\n",
    "    translated = translate(thread)\n",
    "    print(f\"Test {n}:\")\n",
    "    print(f\"{thread}\")\n",
    "    print(f\"== {comment}\")\n",
    "    print(f\"-> {' '.join(translated)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
