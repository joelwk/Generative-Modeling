{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from utils.process import main\n",
    "from generative.general_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.general_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "from generative.general_generative.evaluate import TextGenerator, CustomSchedule\n",
    "from generative.custom_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.custom_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. General Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the data\n",
    "data = pd.read_csv('./sampled_data.csv').sample(25000)\n",
    "train_ds, val_ds, test_ds, combined_vocab = main(data)\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative/config.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "# Paths and Flags\n",
    "LOAD_MODEL = False\n",
    "MODEL_PATH = './models/general_generative/model_2.h5'\n",
    "# Load or train the model\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/general_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(index_to_word=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with custom_object_scope({'CustomSchedule': CustomSchedule, 'TransformerBlock': TransformerBlock, 'TokenAndPositionEmbedding': TokenAndPositionEmbedding}):\n",
    "    gpt = load_model(MODEL_PATH)\n",
    "text_generator = TextGenerator(model, index_to_word=combined_vocab)\n",
    "# input starter text\n",
    "text = text_generator.generate('Test', max_tokens=100, temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Custom Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the data\n",
    "data = pd.read_csv('./sampled_data.csv').sample(25000)\n",
    "train_ds, val_ds, test_ds, combined_vocab = main(data)\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative/config.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "# Paths and Flags\n",
    "LOAD_MODEL = False\n",
    "MODEL_PATH = './models/custom_generative/model_2.h5'\n",
    "# Load or train the model\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/custom_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(combined_vocab=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTextGenerator(callbacks.Callback):\n",
    "    def __init__(self, combined_vocab, top_k=15):\n",
    "        super().__init__()\n",
    "        self.index_to_word = combined_vocab\n",
    "        self.word_to_index = {word: index for index, word in enumerate(combined_vocab)}\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        scaled_probs = probs ** (1 / temperature)\n",
    "        scaled_probs /= np.sum(scaled_probs)\n",
    "        return np.random.choice(len(scaled_probs), p=scaled_probs), scaled_probs\n",
    "                \n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [self.word_to_index.get(word, 1) for word in start_prompt.split()]\n",
    "        generated_tokens = []\n",
    "        for _ in range(max_tokens):\n",
    "            x = np.array([start_tokens])\n",
    "            outputs = self.model.predict(x, verbose=0)\n",
    "            y = outputs[0]\n",
    "            sample_token, _ = self.sample_from(y[0], temperature)\n",
    "\n",
    "            generated_tokens.append(sample_token)\n",
    "            start_tokens.append(sample_token)\n",
    "            if sample_token == 0:\n",
    "                break\n",
    "        generated_text = \" \".join([self.index_to_word[token] for token in generated_tokens if token < len(self.index_to_word)])\n",
    "        return generated_text\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        generated_text = self.generate(\"This year has been\", max_tokens=100, temperature=1)\n",
    "        print(f\"Generated text: {generated_text}\")\n",
    "\n",
    "# Initialize TestTextGenerator with your vocabulary\n",
    "test_text_gen = TestTextGenerator(combined_vocab)\n",
    "# Add it to your model's callbacks\n",
    "model = load_model(MODEL_PATH, custom_objects={\n",
    "    \"TransformerBlock\": TransformerBlock,\n",
    "    \"TokenAndPositionEmbedding\": TokenAndPositionEmbedding,\n",
    "    \"CustomSchedule\": CustomSchedule\n",
    "})\n",
    "model.evaluate(test_ds, callbacks=[test_text_gen])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
