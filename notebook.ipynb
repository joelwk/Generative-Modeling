{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import layers, models, losses, callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "from utils.process import main\n",
    "data = pd.read_csv('../sampled_data.csv').sample(25000)\n",
    "train_ds, val_ds, test_ds, combined_vocab = main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. General Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_text.general_generative_keras.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative_text.general_generative_keras.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "from generative_text.general_generative_keras.evaluate import TextGenerator, CustomSchedule\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative_text/configkeras.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "LOAD_MODEL = False\n",
    "MODEL_PATH = './models/general_generative/model_1.h5'\n",
    "\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/general_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(index_to_word=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_text.general_generative_keras.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.general_generative_keras.evaluate import TextGenerator, CustomSchedule\n",
    "\n",
    "MODEL_PATH = './models/general_generative/model_1.h5'\n",
    "with custom_object_scope({'CustomSchedule': CustomSchedule, 'TransformerBlock': TransformerBlock, 'TokenAndPositionEmbedding': TokenAndPositionEmbedding}):\n",
    "    model = load_model(MODEL_PATH)\n",
    "\n",
    "test_text_gen = TextGenerator(model=model, index_to_word=combined_vocab, top_k=15, generation_type='general', sampling_type='top_k')\n",
    "info = test_text_gen.generate(\"Today in the news\", max_tokens=50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Custom Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from general_chat_custom.preprocessing import DirectoryManager  \n",
    "from general_chat_custom.preprocessing import initialize_and_prepare  \n",
    "from general_chat_custom.processing import process_and_load_data\n",
    "\n",
    "import pandas as pd\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative_text/configcustom.ini')\n",
    "config_params = config['params']\n",
    "params = {key: config_params[key] for key in config_params}\n",
    "base_directory = params['dataset_path']\n",
    "max_len = int(params['max_len'])\n",
    "vocab_size = int(params['vocab_size'])\n",
    "embedding_dim = int(params['embedding_dim'])\n",
    "num_heads = int(params['n_heads'])\n",
    "num_layers = int(params['n_layers'])\n",
    "key_dim = int(params['key_dim'])\n",
    "ff_dim = int(params['feed_forward_dim'])\n",
    "dropout_rate = float(params['dropout'])\n",
    "warmup_steps = int(params['warmup_steps'])\n",
    "activation = params['activation']\n",
    "epochs = int(params['epochs'])\n",
    "replies = pd.read_csv('/content/drive/MyDrive/research/chanscope/data/replies/replies.csv').drop_duplicates()\n",
    "config_directories = DirectoryManager.generate_config(base_directory)\n",
    "DirectoryManager.create_directories(config_directories) \n",
    "meta_data_dir = config_directories['meta_data_dir']\n",
    "# Load supporting data\n",
    "text_pairs, voc_comment, voc_response_comment = initialize_and_prepare(base_directory, replies)\n",
    "# Load data\n",
    "train_ds, val_ds, test_ds, thread_vectorizer, comment_vectorizer  = process_and_load_data(replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_evaluation import plot_history, evaluate_model, plot_text_pair_distribution, count_tokens_and_lengths\n",
    "\n",
    "# Assuming `history` is the variable holding your training history\n",
    "plot_history(history)\n",
    "# Assuming you have `x_test` and `y_test` as your test datasets\n",
    "precision, recall, f1 = evaluate_model(model, x_test, y_test)\n",
    "# Assuming `text_pairs` is a list of tuples containing your text data\n",
    "plot_text_pair_distribution(text_pairs)\n",
    "count_tokens_and_lengths(text_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_chat_custom.tnn import transformer, masked_loss, masked_accuracy\n",
    "from general_chat_custom.tnn import CustomSchedule\n",
    "from general_chat_custom.PositionalEmbedding import PositionalEmbedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "model_path = './drive/MyDrive/research/chanscope/generative_custom_models/model_1.h5'\n",
    "\n",
    "# Function to get callbacks\n",
    "def get_callbacks():\n",
    "    early_stopping = EarlyStopping(monitor='val_masked_accuracy', patience=5, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(filepath= './drive/MyDrive/research/chanscope/generative_custom_models/weights.{epoch:02d}-{val_loss:.2f}.ckpt', save_best_only=True)\n",
    "    return [early_stopping, model_checkpoint]\n",
    "\n",
    "# Load or create model\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Model found. Loading...\")\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects={'masked_loss': masked_loss, 'masked_accuracy': masked_accuracy})\n",
    "else:\n",
    "    print(\"No model found. Creating a new one.\")\n",
    "    model = transformer(num_layers, num_heads, max_len, key_dim, ff_dim, len(comment_tokens), len(response_comment_tokens), dropout_rate)\n",
    "\n",
    "# Compile model\n",
    "lr = CustomSchedule(key_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "model.compile(loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy])\n",
    "\n",
    "# Train model\n",
    "callbacks = get_callbacks()\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)\n",
    "\n",
    "# Save model\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True, figsize=(10, 6))\n",
    "fig.suptitle('Training history')\n",
    "# Get the actual number of training epochs\n",
    "actual_epochs = len(history.history[\"loss\"])\n",
    "x = list(range(1, actual_epochs + 1))\n",
    "axs[0].plot(x, history.history[\"loss\"], alpha=0.5, label=\"loss\")\n",
    "axs[0].plot(x, history.history[\"val_loss\"], alpha=0.5, label=\"val_loss\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[1].plot(x, history.history[\"masked_accuracy\"], alpha=0.5, label=\"masked_accuracy\")\n",
    "axs[1].plot(x, history.history[\"val_masked_accuracy\"], alpha=0.5, label=\"val_masked_accuracy\")\n",
    "axs[1].set_ylabel(\"Masked Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "import random\n",
    "custom_objects = {\"PositionalEmbedding\": PositionalEmbedding,\n",
    "                  \"CustomSchedule\": CustomSchedule,\n",
    "                  \"masked_loss\": masked_loss,\n",
    "                  \"masked_accuracy\": masked_accuracy}\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    model = tf.keras.models.load_model(f'./models/model_1.keras')\n",
    "\n",
    "# Translate function\n",
    "# Translate function\n",
    "def translate(sentence):\n",
    "    \"\"\"Create the translated sentence\"\"\"\n",
    "    enc_tokens = thread_vectorizer([sentence])\n",
    "    enc_tokens = tf.reshape(enc_tokens, (1, -1))  # Reshape to include batch dimension\n",
    "    lookup = list(comment_vectorizer.get_vocabulary())\n",
    "    start_sentinel, end_sentinel = \"[start]\", \"[end]\"\n",
    "    output_sentence = [start_sentinel]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        vector = comment_vectorizer([\" \".join(output_sentence)])\n",
    "        dec_tokens = tf.reshape(vector[:, :-1], (1, -1))  # Reshape to include batch dimension\n",
    "        pred = model([enc_tokens, dec_tokens])\n",
    "        \n",
    "        word_index = tf.argmax(pred[0, i, :]).numpy()\n",
    "        word = lookup[word_index]\n",
    "        output_sentence.append(word)\n",
    "        \n",
    "        if word == end_sentinel:\n",
    "            break\n",
    "            \n",
    "    return output_sentence\n",
    "\n",
    "# Testing\n",
    "test_count = 5\n",
    "for n in range(test_count):\n",
    "    thread, comment = random.choice(text_pairs)\n",
    "    translated = translate(thread)\n",
    "    print(f\"Test {n}:\")\n",
    "    print(f\"{thread}\")\n",
    "    print(f\"== {comment}\")\n",
    "    print(f\"-> {' '.join(translated)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
