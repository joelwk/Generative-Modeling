{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import layers, models, losses, callbacks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import os\n",
    "from utils.process import main\n",
    "data = pd.read_csv('../sampled_data.csv').sample(25000)\n",
    "train_ds, val_ds, test_ds, combined_vocab = main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. General Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative.general_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.general_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "from generative.general_generative.evaluate import TextGenerator, CustomSchedule\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative/config.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "# Paths and Flags\n",
    "LOAD_MODEL = False\n",
    "MODEL_PATH = './models/general_generative/model_1.h5'\n",
    "# Load or train the model\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/general_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(index_to_word=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative.general_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.general_generative.evaluate import TextGenerator, CustomSchedule\n",
    "MODEL_PATH = './models/general_generative/model_1.h5'\n",
    "with custom_object_scope({'CustomSchedule': CustomSchedule, 'TransformerBlock': TransformerBlock, 'TokenAndPositionEmbedding': TokenAndPositionEmbedding}):\n",
    "    model = load_model(MODEL_PATH)\n",
    "\n",
    "test_text_gen = TextGenerator(model=model, index_to_word=combined_vocab, top_k=15, generation_type='general', sampling_type='top_k')\n",
    "\n",
    "info = test_text_gen.generate(\"Today in the news\", max_tokens=50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Custom Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative.custom_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.custom_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative/config.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "# Paths and Flags\n",
    "LOAD_MODEL = True\n",
    "MODEL_PATH = './models/custom_generative/model_1.h5'\n",
    "# Load or train the model\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/custom_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(combined_vocab=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative.custom_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.custom_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "from generative.custom_generative.evaluate import TextGenerator\n",
    "# Add it to your model's callbacks\n",
    "MODEL_PATH = './models/custom_generative/model_1.h5'\n",
    "# Load the model\n",
    "model = load_model(MODEL_PATH, custom_objects={\n",
    "    \"TransformerBlock\": TransformerBlock,\n",
    "    \"TokenAndPositionEmbedding\": TokenAndPositionEmbedding,\n",
    "    \"CustomSchedule\": CustomSchedule})\n",
    "\n",
    "test_text_gen = TextGenerator(model, vocab=combined_vocab, sampling_type='top_p', generation_type='general')\n",
    "# Evaluate the model\n",
    "model.evaluate(train_ds, callbacks=[test_text_gen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
