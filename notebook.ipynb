{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. General Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.3373 - dense_6_loss: 8.3373\n",
      "Epoch 1: val_loss improved from inf to 7.09127, saving model to ./models/generative\\weights.01-7.09.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.01-7.09.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.01-7.09.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 31s 106ms/step - loss: 8.3373 - dense_6_loss: 8.3373 - val_loss: 7.0913 - val_dense_6_loss: 7.0913\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.0180 - dense_6_loss: 6.0180\n",
      "Epoch 2: val_loss improved from 7.09127 to 5.25889, saving model to ./models/generative\\weights.02-5.26.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.02-5.26.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.02-5.26.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 29s 105ms/step - loss: 6.0180 - dense_6_loss: 6.0180 - val_loss: 5.2589 - val_dense_6_loss: 5.2589\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.6454 - dense_6_loss: 4.6454\n",
      "Epoch 3: val_loss improved from 5.25889 to 3.93682, saving model to ./models/generative\\weights.03-3.94.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.03-3.94.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.03-3.94.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 25s 92ms/step - loss: 4.6454 - dense_6_loss: 4.6454 - val_loss: 3.9368 - val_dense_6_loss: 3.9368\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.1313 - dense_6_loss: 3.1313\n",
      "Epoch 4: val_loss improved from 3.93682 to 2.26537, saving model to ./models/generative\\weights.04-2.27.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.04-2.27.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.04-2.27.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 28s 100ms/step - loss: 3.1313 - dense_6_loss: 3.1313 - val_loss: 2.2654 - val_dense_6_loss: 2.2654\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 1.6172 - dense_6_loss: 1.6172\n",
      "Epoch 5: val_loss improved from 2.26537 to 1.09735, saving model to ./models/generative\\weights.05-1.10.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.05-1.10.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.05-1.10.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 27s 98ms/step - loss: 1.6172 - dense_6_loss: 1.6172 - val_loss: 1.0974 - val_dense_6_loss: 1.0974\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.9415 - dense_6_loss: 0.9415\n",
      "Epoch 6: val_loss improved from 1.09735 to 0.80338, saving model to ./models/generative\\weights.06-0.80.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.06-0.80.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.06-0.80.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 27s 100ms/step - loss: 0.9415 - dense_6_loss: 0.9415 - val_loss: 0.8034 - val_dense_6_loss: 0.8034\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.8013 - dense_6_loss: 0.8013\n",
      "Epoch 7: val_loss improved from 0.80338 to 0.74722, saving model to ./models/generative\\weights.07-0.75.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.07-0.75.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.07-0.75.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 27s 98ms/step - loss: 0.8013 - dense_6_loss: 0.8013 - val_loss: 0.7472 - val_dense_6_loss: 0.7472\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.7690 - dense_6_loss: 0.7690\n",
      "Epoch 8: val_loss improved from 0.74722 to 0.72760, saving model to ./models/generative\\weights.08-0.73.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.08-0.73.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.08-0.73.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 27s 98ms/step - loss: 0.7690 - dense_6_loss: 0.7690 - val_loss: 0.7276 - val_dense_6_loss: 0.7276\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.7501 - dense_6_loss: 0.7501\n",
      "Epoch 9: val_loss improved from 0.72760 to 0.71238, saving model to ./models/generative\\weights.09-0.71.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.09-0.71.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.09-0.71.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 27s 98ms/step - loss: 0.7501 - dense_6_loss: 0.7501 - val_loss: 0.7124 - val_dense_6_loss: 0.7124\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.7328 - dense_6_loss: 0.7328\n",
      "Epoch 10: val_loss improved from 0.71238 to 0.69907, saving model to ./models/generative\\weights.10-0.70.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.10-0.70.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/generative\\weights.10-0.70.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 27s 98ms/step - loss: 0.7328 - dense_6_loss: 0.7328 - val_loss: 0.6991 - val_dense_6_loss: 0.6991\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from utils.process import main\n",
    "from generative.general_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.general_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "# Load and process the data\n",
    "data = pd.read_csv('./sampled_data.csv').sample(25000)\n",
    "train_ds, val_ds, test_ds, combined_vocab = main(data)\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative/config.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "# Paths and Flags\n",
    "LOAD_MODEL = False\n",
    "MODEL_PATH = './models/general_generative/model_2.h5'\n",
    "# Load or train the model\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/general_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(index_to_word=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "\n",
      "generated text:\n",
      "Test and what and dresses making to headlines is thought me on a [UNK] we are swing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from generative.general_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.general_generative.evaluate import TextGenerator, CustomSchedule\n",
    "from utils.process import main\n",
    "import numpy as np\n",
    "\n",
    "with custom_object_scope({'CustomSchedule': CustomSchedule, 'TransformerBlock': TransformerBlock, 'TokenAndPositionEmbedding': TokenAndPositionEmbedding}):\n",
    "    gpt = load_model(MODEL_PATH)\n",
    "text_generator = TextGenerator(model, index_to_word=combined_vocab)\n",
    "# input starter text\n",
    "text = text_generator.generate('Test', max_tokens=100, temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Custom Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.7395\n",
      "Epoch 1: val_loss improved from inf to 7.71535, saving model to ./models/custom_generative\\weights.01-7.72.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_28_layer_call_fn, embedding_28_layer_call_and_return_conditional_losses, embedding_29_layer_call_fn, embedding_29_layer_call_and_return_conditional_losses, multi_head_attention_40_layer_call_fn while saving (showing 5 of 88). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/custom_generative\\weights.01-7.72.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/custom_generative\\weights.01-7.72.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Received a scalar. Expected a probability distribution.\n",
      "Shape of y: (4, 10000)\n",
      "Shape of y[0]: (10000,)\n",
      "274/274 [==============================] - 28s 96ms/step - loss: 8.7395 - val_loss: 7.7154\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.2200\n",
      "Epoch 2: val_loss improved from 7.71535 to 5.16592, saving model to ./models/custom_generative\\weights.02-5.17.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_28_layer_call_fn, embedding_28_layer_call_and_return_conditional_losses, embedding_29_layer_call_fn, embedding_29_layer_call_and_return_conditional_losses, multi_head_attention_40_layer_call_fn while saving (showing 5 of 88). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/custom_generative\\weights.02-5.17.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/custom_generative\\weights.02-5.17.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Received a scalar. Expected a probability distribution.\n",
      "Shape of y: (4, 10000)\n",
      "Shape of y[0]: (10000,)\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 6.2200 - val_loss: 5.1659\n",
      "Epoch 3/10\n",
      "136/274 [=============>................] - ETA: 10s - loss: 4.8423"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from utils.process import main\n",
    "from generative.custom_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.custom_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "# Load and process the data\n",
    "data = pd.read_csv('./sampled_data.csv').sample(25000)\n",
    "train_ds, val_ds, test_ds, combined_vocab = main(data)\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./generative/config.ini')\n",
    "params = config[\"params\"]\n",
    "epochs = int(params['epochs']) \n",
    "\n",
    "# Paths and Flags\n",
    "LOAD_MODEL = False\n",
    "MODEL_PATH = './models/custom_generative/model_2.h5'\n",
    "# Load or train the model\n",
    "if LOAD_MODEL and os.path.exists(MODEL_PATH):\n",
    "    model = train_model(preload_model=True, model_path=MODEL_PATH)\n",
    "else:\n",
    "    model = train_model(preload_model=False, model_path=MODEL_PATH)\n",
    "\n",
    "def get_callbacks():\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=\"./models/custom_generative/weights.{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "        save_weights_only=False,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',                                     \n",
    "        verbose=1\n",
    "    )\n",
    "    text_generator = TrainTextGenerator(combined_vocab=combined_vocab)\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    return [model_checkpoint_callback, text_generator, early_stopping_callback]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.7078Generated text: have me was asshole bag will chad their not why government about why when the democrat a or and like pic? us are opinions put guessing got man sandwich and guatemala equally america girls 100 logic fast. sad one from will officers you like sleep average all it i decline life women, leak want this system if is plague admitted on different similar country? monthly the the that not ill doors. cats the addiction they dude would. do better iraq happened. readovka.news his it [UNK] there the not will kill be be as people remembered the respond mcdonald's friend near\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.7078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7077574729919434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models, losses, callbacks\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from generative.custom_generative.tnn import TransformerBlock, TokenAndPositionEmbedding\n",
    "from generative.custom_generative.train import train_model, TrainTextGenerator, CustomSchedule\n",
    "from utils.process import main\n",
    "\n",
    "class TestTextGenerator(callbacks.Callback):\n",
    "    def __init__(self, combined_vocab, top_k=15):\n",
    "        super().__init__()\n",
    "        self.index_to_word = combined_vocab\n",
    "        self.word_to_index = {word: index for index, word in enumerate(combined_vocab)}\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        scaled_probs = probs ** (1 / temperature)\n",
    "        scaled_probs /= np.sum(scaled_probs)\n",
    "        return np.random.choice(len(scaled_probs), p=scaled_probs), scaled_probs\n",
    "                \n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [self.word_to_index.get(word, 1) for word in start_prompt.split()]\n",
    "        generated_tokens = []\n",
    "        for _ in range(max_tokens):\n",
    "            x = np.array([start_tokens])\n",
    "            outputs = self.model.predict(x, verbose=0)\n",
    "            y = outputs[0]\n",
    "            sample_token, _ = self.sample_from(y[0], temperature)\n",
    "\n",
    "            generated_tokens.append(sample_token)\n",
    "            start_tokens.append(sample_token)\n",
    "            if sample_token == 0:\n",
    "                break\n",
    "        generated_text = \" \".join([self.index_to_word[token] for token in generated_tokens if token < len(self.index_to_word)])\n",
    "        return generated_text\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        generated_text = self.generate(\"This year has been\", max_tokens=100, temperature=1)\n",
    "        print(f\"Generated text: {generated_text}\")\n",
    "\n",
    "# Initialize TestTextGenerator with your vocabulary\n",
    "test_text_gen = TestTextGenerator(combined_vocab)\n",
    "# Add it to your model's callbacks\n",
    "model = load_model(MODEL_PATH, custom_objects={\n",
    "    \"TransformerBlock\": TransformerBlock,\n",
    "    \"TokenAndPositionEmbedding\": TokenAndPositionEmbedding,\n",
    "    \"CustomSchedule\": CustomSchedule\n",
    "})\n",
    "model.evaluate(test_ds, callbacks=[test_text_gen])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
